import logging
import json
import warnings
from typing import List, Optional
import os # Ensure os is imported as it is used
from pathlib import Path

# from dotenv import load_dotenv

# Suppress Pydantic deprecation warnings
warnings.filterwarnings("ignore", category=DeprecationWarning, module="pydantic")

# LangGraph vÃ  LangChain
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage

# Import tá»« module nÃ y
from .schemas import AgentState, MeetingOutput, ReflectionOutput
from .prompts import ANALYSIS_PROMPT, REFLECTION_PROMPT, REFINEMENT_PROMPT
from .tools import (
    format_email_body_for_assignee, 
    get_emails_from_participants, 
    transcribe_audio, 
    create_tasks, 
    send_notification
)
from ...models.models import call_llm

logger = logging.getLogger(__name__)

# Global memory checkpointer to persist state across instances (requests)
_memory_store = MemorySaver()

class MeetingToTaskAgent:
    """
    Agent xá»­ lÃ½ meeting recordings vÃ  táº¡o tasks tá»± Ä‘á»™ng
    """
    
    def __init__(self):
        """
        Khá»Ÿi táº¡o agent
    
        Args:
            provider_name: TÃªn provider LLM Ä‘á»ƒ sá»­ dá»¥ng
        """
        self.model = call_llm(
            model_provider='gemini',
            model_name='gemini-2.5-flash',
            temperature=0.3,
            top_p=0.7,
        )
        self.memory = _memory_store # Use global instance
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """XÃ¢y dá»±ng workflow graph"""
        builder = StateGraph(AgentState)
        
        # ThÃªm cÃ¡c nodes
        builder.add_node('stt', self._stt)
        builder.add_node('analysis', self._analysis)
        builder.add_node('reflection', self._reflection)
        builder.add_node('refinement', self._refinement)
        builder.add_node('create_tasks', self._create_tasks)
        # builder.add_node('notification', self._notification)
        
        # Thiáº¿t láº­p entry point
        builder.set_entry_point('stt')
        
        # ThÃªm cÃ¡c edges
        builder.add_edge('stt', 'analysis')
        builder.add_edge('analysis', 'reflection')
        
        # Conditional edge: reflection -> refine hoáº·c create_tasks
        builder.add_conditional_edges(
            'reflection',
            self._should_create_tasks,
            {
                False: 'refinement',
                True: 'create_tasks'
            }
        )
        
        # Edge: refinement quay láº¡i reflection Ä‘á»ƒ kiá»ƒm tra láº¡i
        builder.add_edge('refinement', 'reflection')
        
        # Edge: create_tasks -> notification -> END
        # builder.add_edge('create_tasks', 'notification')
        # builder.add_edge('notification', END)
        builder.add_edge('create_tasks', END)
        # Compile graph vá»›i memory vÃ  interrupt_before
        return builder.compile(
            checkpointer=self.memory,
            interrupt_before=['create_tasks']
        )
    
    # ==================== NODES ====================
    
    def _stt(self, state: AgentState):
        """Node 1: Chuyá»ƒn Ä‘á»•i Ã¢m thanh thÃ nh vÄƒn báº£n"""
        # Check if transcript is already provided in state (e.g. from API)
        if state.get('transcript'):
            logger.info(f"  ğŸ“ Using provided transcript ({len(state['transcript'])} chars)")
            return {'transcript': state['transcript']}
            
        logger.info("\n[NODE 1] Äang chuyá»ƒn Ä‘á»•i Ã¢m thanh thÃ nh vÄƒn báº£n...")
        
        # In production: Audio should be downloaded from S3 or passed as bytes.
        # Here we assume audio_file_path is accessible (e.g. shared volume or local dev)
        
        logger.info(f"  ğŸ¤ Transcribing audio: {state['audio_file_path']}")
        
        transcript = transcribe_audio(
            state['audio_file_path'], 
            provider='gemini', 
            use_mock=False
        )
        
        logger.info(f"  âœ… Transcript: {len(transcript)} kÃ½ tá»±")
        return {'transcript': transcript}
    
    def _analysis(self, state: AgentState):
        """Node 2: PhÃ¢n tÃ­ch vÃ  táº¡o Summary + Action Items"""
        logger.info("\n[NODE 2] Äang phÃ¢n tÃ­ch vÃ  táº¡o Summary...")
        
        # Pass the entire metadata object to the prompt to make the agent more robust
        # to changes in the metadata structure.
        metadata_str = json.dumps(state.get('meeting_metadata', {}), indent=2, ensure_ascii=False)
        
        messages = [
            HumanMessage(content=ANALYSIS_PROMPT.format(
                metadata=metadata_str,
                transcript=state['transcript']
            ))
        ]
        
        response = self.model.with_structured_output(MeetingOutput).invoke(messages)
        
        if response is None:
            raise ValueError("LLM failed to generate structured output for meeting analysis")
        
        if not hasattr(response, 'action_items') or response.action_items is None or response.summary is None:
            raise ValueError("LLM response missing required fields (summary or action_items)")
        
        # Chuyá»ƒn Ä‘á»•i action items sang dict
        action_items_list = [item.model_dump() for item in response.action_items]
        
        logger.info(f"  âœ… Summary: {len(response.summary)} kÃ½ tá»±")
        logger.info(f"  âœ… Action Items: {len(action_items_list)} items")
        for item in action_items_list:
            logger.info(f"     - {item.get('assignee', 'N/A')}: {item.get('title', '')[:40]}...")
        
        return {
            'summary': response.summary,
            'action_items': action_items_list,
        }
    
    def _reflection(self, state: AgentState):
        """Node 3: Tá»± kiá»ƒm tra vÃ  phÃ¡t hiá»‡n lá»—i"""
        logger.info("\n[NODE 3] Äang tá»± kiá»ƒm tra cháº¥t lÆ°á»£ng...")
        
        # Pass the entire metadata object to the prompt for context.
        metadata_str = json.dumps(state.get('meeting_metadata', {}), indent=2, ensure_ascii=False)
        action_items_str = json.dumps(state['action_items'], indent=2, ensure_ascii=False)
        
        messages = [
            HumanMessage(content=REFLECTION_PROMPT.format(
                metadata=metadata_str,
                summary=state['summary'],
                action_items=action_items_str
            ))
        ]
        
        response = self.model.with_structured_output(ReflectionOutput).invoke(messages)
        
        logger.info(f"  ğŸ“ Critique: {response.critique[:100]}...")
        logger.info(f"  ğŸ¯ Decision: {response.decision}")
        
        return {'critique': response.critique, 'reflect_decision': response.decision}
    
    def _refinement(self, state: AgentState):
        """Node 4: Tinh chá»‰nh dá»±a trÃªn pháº£n há»“i"""
        logger.info("\n[NODE 4] Tinh chá»‰nh Summary...")
        
        # Pass the entire metadata object to the prompt for context.
        metadata_str = json.dumps(state.get('meeting_metadata', {}), indent=2, ensure_ascii=False)
        action_items_str = json.dumps(state['action_items'], indent=2, ensure_ascii=False)
        
        messages = [
            HumanMessage(content=REFINEMENT_PROMPT.format(
                metadata=metadata_str,
                draft_summary=state['summary'],
                draft_action_items=action_items_str,
                critique=state['critique'],
                transcript=state['transcript']
            ))
        ]
        
        response = self.model.with_structured_output(MeetingOutput).invoke(messages)
        
        refined_action_items = [item.model_dump() for item in response.action_items]
        revision_count = state.get('revision_count', 0) + 1
        
        logger.info(f"  ğŸ”„ Revision #{revision_count}")
        
        return {
            'summary': response.summary,
            'action_items': refined_action_items,
            'revision_count': revision_count
        }
    
    def _create_tasks(self, state: AgentState):
        """Node 5: Táº¡o tasks trong há»‡ thá»‘ng backend"""
        logger.info("\n[NODE 5] Táº¡o tasks...")
        logger.info('='*100)
        summary: str
        action_items = state.get('action_items', [])
        meeting_metadata = state.get('meeting_metadata', {})
        participants = meeting_metadata.get('participants', [])
        
        # Extract project_id and author_user_id from meeting metadata
        project_id = meeting_metadata.get('project_id')
        author_user_id = meeting_metadata.get('author_id')
        
        user_mapping = {}
        for p in participants:
            # Try multiple keys for name/username
            username = p.get('name') or p.get('username') or ''
            user_id = p.get('id') or p.get('userId')
            
            if username and user_id:
                user_mapping[username.lower().strip()] = user_id
        
        # Call API to create tasks
        tasks = create_tasks(
            action_items=action_items,
            project_id=project_id,
            author_user_id=author_user_id,
            user_mapping=user_mapping
        )
        
        logger.info(f"  ğŸ“Š Created {len(tasks)} tasks")
        return {'tasks_created': tasks}
    
    def _notification(self, state: AgentState):
        """Node 6: Gá»­i thÃ´ng bÃ¡o tá»›i tá»«ng assignee"""
        logger.info("\n[NODE 6] Gá»­i notification...")
        logger.info('='*100)
        
        summary = state.get('summary')
        action_items = state.get('action_items', [])
        meeting_metadata = state.get('meeting_metadata', {})
        participants = meeting_metadata.get('participants', [])
        
        # Láº¥y email mapping tá»« participants
        email_map = get_emails_from_participants(participants)
        
        logger.info(f"  ğŸ‘¥ Participants vá»›i email: {list(email_map.keys())}")
        
        # Gá»­i email cho tá»«ng task
        results = []
        for task in action_items:
            assignee = task.get('assignee', '').lower()
            
            # Skip náº¿u lÃ  Unassigned
            if assignee == 'unassigned' or not assignee:
                logger.info(f"  â­ï¸ Skip task khÃ´ng cÃ³ assignee: {task.get('title', '')[:30]}...")
                continue
            
            email = email_map.get(assignee)
            
            if not email:
                logger.info(f"  âš ï¸ KhÃ´ng tÃ¬m tháº¥y email cho: {assignee}")
                results.append({
                    "assignee": assignee,
                    "email": None,
                    "title": task.get('title', ''),
                    "status": "skipped",
                    "reason": "Email not found in participants"
                })
                continue
            
            # Format email riÃªng cho task nÃ y
            email_body = format_email_body_for_assignee(
                assignee_name=assignee.title(),
                assignee_task=task,
                summary=summary,
                meeting_metadata=meeting_metadata
            )
            
            result = send_notification(
                email_body=email_body,
                receiver_email=email,
                subject=f"[Action Required] {meeting_metadata.get('title', 'Meeting')} - CÃ´ng viá»‡c cho {assignee.title()}"
            )
            
            results.append({
                "assignee": assignee,
                "email": email,
                "title": task.get('title', ''),
                "status": "sent" if result else "failed"
            })
        
        sent_count = len([r for r in results if r['status'] == 'sent'])
        logger.info(f"\n  ğŸ“Š ÄÃ£ gá»­i {sent_count}/{len(results)} email")
        
        return {'notification_sent': results}
    
    # ==================== CONDITIONAL LOGIC ====================
    
    def _should_create_tasks(self, state: AgentState) -> bool:
        """Quyáº¿t Ä‘á»‹nh cÃ³ cáº§n tinh chá»‰nh dá»±a trÃªn critique khÃ´ng."""
        decision = state.get('reflect_decision', '')
        max_revisions = state.get('max_revisions', 2)
        revision_count = state.get('revision_count', 0)
        
        # Accept náº¿u decision lÃ  accept HOáº¶C Ä‘Ã£ Ä‘áº¡t max revisions
        if decision == 'accept':
            return True
        if revision_count >= max_revisions:
            logger.info(f"  âš ï¸ Äáº¡t max revisions ({max_revisions}), tiáº¿p tá»¥c...")
            return True
        return False
    
    # ==================== PUBLIC METHODS ====================
    
    def run(self, audio_file_path: str, meeting_metadata: Optional[dict] = None, 
            max_revisions: int = 2, thread_id: str = '1', transcript: Optional[str] = None):
        """
        Cháº¡y workflow Ä‘áº¿n Ä‘iá»ƒm Human Review
        
        Args:
            audio_file_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file Ã¢m thanh
            meeting_metadata: Metadata cá»§a cuá»™c há»p (bao gá»“m participants)
            max_revisions: Sá»‘ láº§n tá»‘i Ä‘a cho phÃ©p tinh chá»‰nh
            thread_id: ID cá»§a thread cho memory
            transcript: (Optional) Transcript text if available
            
        Returns:
            Tuple[dict, dict]: (current_state values, thread_config)
        """
        initial_state = {
            'audio_file_path': audio_file_path,
            'meeting_metadata': meeting_metadata or {},
            'max_revisions': max_revisions,
            'revision_count': 0,
            'transcript': transcript,
        }
        
        thread = {'configurable': {'thread_id': thread_id}}
        
        logger.info("\nğŸš€ Starting Meeting-to-Task Agent...")
        logger.info("="*100)
        
        # Cháº¡y Ä‘áº¿n Ä‘iá»ƒm interrupt
        for event in self.graph.stream(initial_state, thread):
            pass  # Events Ä‘Ã£ Ä‘Æ°á»£c print trong nodes

        current_state = self.graph.get_state(thread)
        return current_state.values, thread
    
    def continue_after_review(self, thread, updated_summary: str = None, 
                              updated_action_items: list = None):
        """Cáº­p nháº­t state vÃ  tiáº¿p tá»¥c workflow sau human review"""
        if updated_summary or updated_action_items:
            updates = {}
            if updated_summary:
                updates['summary'] = updated_summary
            if updated_action_items:
                updates['action_items'] = updated_action_items
            self.graph.update_state(thread, updates)
        
        logger.info("\nâ–¶ï¸ Continuing after human review...")
        logger.info("="*100)
        
        for event in self.graph.stream(None, thread):
            pass
        
        final_state = self.graph.get_state(thread)
        return final_state.values
    
    def get_graph(self):
        """Hiá»ƒn thá»‹ graph dÆ°á»›i dáº¡ng hÃ¬nh áº£nh"""
        from IPython.display import Image, display
        
        img = self.graph.get_graph().draw_mermaid_png()
        return display(Image(img))